# Pitfalls Research

**Domain:** ZK Credential Verification on Starknet (Noir + Garaga + Cairo + Browser WASM Proving)
**Researched:** 2026-02-14
**Confidence:** MEDIUM (verified across official docs, GitHub releases, benchmarks, and audit guides; some version-specific claims are LOW confidence due to beta ecosystem instability)

---

## Critical Pitfalls

Mistakes that cause rewrites, demo failures, or blown deadlines.

### Pitfall 1: Garaga Version Mismatch Between CLI, Noir, and Barretenberg

**What goes wrong:**
The Garaga v1.0.1 documentation specifies exact version pins: Noir `1.0.0-beta.16` and Barretenberg `3.0.0-nightly.20251104`. The project PRD specifies Noir `1.0.0-beta.18` and `@noir-lang/backend_barretenberg 0.36.0`. These are different version families. Garaga's own documentation warns: "Use the same Garaga SDK version (pip/npm/Rust) that generated your verifier contract. Mismatched versions produce incompatible calldata and cause verification to fail." Additionally, the Garaga CLI uses `bb` (the native Barretenberg binary) for VK generation, while the browser uses `@noir-lang/backend_barretenberg` (the WASM npm package) for proving. These two must produce compatible proof formats, and version drift between them is silent until on-chain verification fails.

**Why it happens:**
The Noir ecosystem is in beta with rapid version churn. The PRD was written using the latest available Noir beta, while Garaga pins to a specific tested combination. Developers naturally want the latest Noir features without realizing Garaga's compatibility window is narrower. The `bb` CLI binary and the npm `backend_barretenberg` package have separate versioning schemes that are not obviously correlated.

**How to avoid:**
1. Use EXACTLY the versions Garaga v1.0.1 documents: Noir `1.0.0-beta.16`, Barretenberg `3.0.0-nightly.20251104` via `bbup --version 3.0.0-nightly.20251104`.
2. For the browser npm package, use `@noir-lang/noir_js@1.0.0-beta.15` and `@aztec/bb.js@3.0.0-nightly.20251104` (not `@noir-lang/backend_barretenberg 0.36.0` which is from an older versioning scheme).
3. Run the full loop (compile -> prove -> generate calldata -> verify on-chain) in the FIRST day before writing any application logic.
4. Pin ALL versions in a single `versions.env` file and reference it from every tool invocation.
5. Keep `garaga` Python package, `garaga` Scarb dependency, and any npm garaga package at the same `1.0.1` version.

**Warning signs:**
- `garaga calldata` produces output but on-chain `verify_ultra_keccak_zk_honk_proof` returns error
- Proof verifies locally with `bb verify` but fails on-chain
- VK generated by `bb write_vk` has different size than expected by Garaga contract
- Error messages mentioning "invalid proof" or "malformed calldata" during verification

**Phase to address:**
Phase 0 / Day 1 -- Environment setup. Validate the full prove-verify loop end-to-end before writing a single line of circuit logic.

**Recovery cost:** HIGH. Discovering this in Week 2 means regenerating ALL verifier contracts, re-testing ALL proofs, and potentially rewriting circuit code if Noir API changed between beta versions. In a 14-day timeline, losing 2-3 days is catastrophic.

---

### Pitfall 2: Circuit Constraint Count Exceeding Browser WASM Proving Ceiling

**What goes wrong:**
Browser-based WASM proving via Barretenberg has a hard ceiling of 2^19 (524,288) constraints due to WASM's 4GB memory limit. The project targets < 50K constraints, which seems safe, but Poseidon2 hashing, Schnorr signature verification, nullifier generation, expiration checks, and attribute comparison can stack up faster than expected. Each Poseidon2 hash adds roughly 600-1200 constraints depending on state size. Schnorr verification over embedded curves adds 5K-8K constraints. If the circuit design is not carefully measured after each addition, you can hit the ceiling or, more practically, hit the 30-second proving time target long before the constraint ceiling.

**Why it happens:**
Developers design circuits feature-first ("I need signature verification, nullifier generation, expiration check, attribute comparison") without measuring constraint counts incrementally. Noir's high-level syntax hides the cost of operations. A single `assert` looks cheap but may compile to thousands of constraints depending on the underlying operation. Benchmark data shows proving time scales in steps: circuits between 2^17 and 2^18 take similar time (~1.7s natively at 2^16, ~20s at 2^20). A circuit at 45K constraints (just under 2^16) proves in ~1.7s natively, but one at 70K constraints (above 2^16) jumps to ~3-5s natively and potentially 15-25s in WASM.

**How to avoid:**
1. Measure constraint count after EVERY feature addition: `nargo info` reports gate count.
2. Set a constraint budget per feature: signature verification (8K), Poseidon2 hashes x3 (3K), nullifier (1K), expiration (0.5K), attribute comparison (0.5K), overhead (2K) = ~15K total target.
3. Test browser proving time after each circuit change, not just at the end.
4. If constraint count exceeds 2^16 (65,536), expect proving time to jump significantly. Stay below 2^16 for the 30-second browser target.
5. Use `unconstrained` functions for witness generation (e.g., computing intermediate values) and constrain only the verification. Example: compute Schnorr verification intermediates unconstrained, then constrain the final check.

**Warning signs:**
- `nargo info` shows gate count growing faster than expected (> 1K per seemingly simple addition)
- Browser proving takes > 10s for a circuit you expected to be fast
- Memory errors or tab crashes during browser proving

**Phase to address:**
Phase 1 -- Circuit development. Establish constraint budget BEFORE coding. Measure after each feature. Have a "circuit too big" contingency plan (drop expiration check first, then simplify nullifier).

**Recovery cost:** HIGH. Refactoring a circuit to reduce constraints often means redesigning the cryptographic approach, not just optimizing code. With Poseidon-Schnorr already chosen as the constraint-minimal approach, there is limited room to optimize further without dropping features.

---

### Pitfall 3: Small-Domain Hash Brute Force on Age Verification

**What goes wrong:**
The age verification circuit proves `age >= threshold` without revealing exact age. But if the circuit exposes a public hash of the age (or any intermediate derived from age), an attacker can brute-force it trivially. Human ages span roughly 0-120 years -- only 121 possible values. Even with Poseidon2, an attacker can hash all 121 values in milliseconds and match against the public output. This completely breaks the privacy guarantee, which is the entire point of the protocol.

**Why it happens:**
This is a fundamental ZK circuit design error documented by OpenZeppelin's Noir circuit safety guide. Developers think "I hashed the secret so it is private" without considering the entropy of the input domain. The credential format includes `attribute_value` as a field, and if this field (or any deterministic function of it) appears as a public input or is derivable from public inputs, privacy is destroyed.

**How to avoid:**
1. NEVER expose any hash or deterministic transformation of a small-domain value as a public output.
2. The credential hash (Poseidon2 over all 8 fields including attribute_value) is safe ONLY if it includes high-entropy fields (like a unique credential ID or issuer secret).
3. The nullifier must be derived from high-entropy secrets (user secret + dApp address), NOT from the attribute value.
4. Public outputs should be limited to: nullifier hash, credential commitment (which includes the issuer signature binding it to high-entropy data), verification result (boolean), and the threshold value (which is chosen by the verifier, not derived from private data).
5. Audit every public output: "Can an attacker enumerate all possible private inputs that produce this output?"

**Warning signs:**
- Any `pub` output in the circuit that is a direct function of a small-domain value (age, membership tier, country code)
- Public outputs that change when the private attribute changes but nothing else does
- Nullifiers or commitments that do not incorporate a high-entropy user secret

**Phase to address:**
Phase 1 -- Circuit design. This must be designed correctly from the start. It is an architectural decision, not a bug to fix later.

**Recovery cost:** HIGH. Fixing this after circuit deployment means changing the circuit structure, regenerating the Garaga verifier, redeploying contracts, and updating all client-side code.

---

### Pitfall 4: Garaga Python 3.10 Requirement Silently Breaking on Newer Python

**What goes wrong:**
The project specifies "Python 3.10 required for Garaga (not 3.11+)." If the developer's system Python is 3.11, 3.12, or 3.14 (increasingly common in 2026), `pip install garaga` may install but then fail at runtime with cryptic errors in native extension modules, or produce incorrect calldata due to subtle integer handling differences. The Garaga SDK uses native Rust extensions (via `garaga_rs`) that are compiled against specific Python ABI versions.

**Why it happens:**
macOS and most Linux distributions now ship with Python 3.12+. Developers often forget to use a version manager. The `pip install garaga` command succeeds without version warnings because pip does not enforce Python version constraints at install time for all packages. The failure surfaces later when running `garaga gen` or `garaga calldata`.

**How to avoid:**
1. Use `pyenv` to install and activate Python 3.10 specifically: `pyenv install 3.10.14 && pyenv local 3.10.14`.
2. Create a dedicated virtualenv: `python3.10 -m venv .venv-garaga && source .venv-garaga/bin/activate && pip install garaga==1.0.1`.
3. Verify Python version before every Garaga command: add `python --version | grep "3.10"` as a pre-check in any Makefile or script.
4. Document this in the project README with exact setup steps.

**Warning signs:**
- `garaga gen` fails with `ImportError` or `ModuleNotFoundError` for native modules
- `garaga calldata` produces output but on-chain verification fails (subtle ABI mismatch)
- `pip install garaga` warns about incompatible wheel or builds from source unexpectedly

**Phase to address:**
Phase 0 -- Environment setup. Set up the Python environment FIRST and validate with `garaga gen --help`.

**Recovery cost:** LOW if caught early (just fix the Python version). MEDIUM if calldata was generated with wrong Python and contracts were already deployed (need to re-run everything).

---

### Pitfall 5: Unconstrained Functions Creating Under-Constrained Circuits

**What goes wrong:**
Noir's `unconstrained` functions execute without generating constraints. If a developer moves computation to unconstrained functions for performance but forgets to add corresponding constrained verification, the circuit becomes unsound. A malicious prover can supply arbitrary values as unconstrained outputs and the proof will still verify. In a credential verification system, this means a prover could forge any verification result.

**Why it happens:**
Developers optimize for constraint count (to hit the browser proving target) by moving expensive operations to unconstrained context. This is a valid optimization pattern, but the "verify the result in constrained context" step is easy to forget. Noir does not warn you if unconstrained outputs are used without constraint checking. The circuit "works" in testing because honest inputs produce correct outputs, but it is not sound.

**How to avoid:**
1. Treat every `unconstrained` function as `unsafe` (Noir is moving toward requiring `unsafe` blocks for this).
2. For every value produced by an unconstrained function, add a constrained assertion that verifies the result. Example: if unconstrained computes `quotient = a / b`, constrain `quotient * b == a`.
3. Write a test with deliberately wrong unconstrained outputs to verify the circuit rejects them.
4. Minimize unconstrained usage. For a circuit targeting < 50K constraints, unconstrained optimization is likely unnecessary. Only reach for it if you hit the constraint ceiling.
5. Code review checklist: grep for `unconstrained` and verify each has a corresponding `assert` in constrained context.

**Warning signs:**
- `unconstrained` functions that produce values used in public outputs without intervening assertions
- Circuit compiles and runs with `nargo test` but has fewer constraints than expected
- Changing unconstrained function logic does not change the constraint count (gate count should change if constraints are properly laid)

**Phase to address:**
Phase 1 -- Circuit development. Establish the rule from the start. Review during circuit PR/code review.

**Recovery cost:** MEDIUM. Adding missing constraints is straightforward IF the circuit design supports it. If the unconstrained function's result cannot be efficiently verified in-circuit, it may require redesign.

---

## Moderate Pitfalls

### Pitfall 6: SharedArrayBuffer / Cross-Origin Isolation Headers Missing

**What goes wrong:**
Barretenberg WASM requires `SharedArrayBuffer` for multi-threaded proving. Browsers restrict `SharedArrayBuffer` unless the page is served with `Cross-Origin-Opener-Policy: same-origin` and `Cross-Origin-Embedder-Policy: require-corp` headers. Without these, `bb.js` initialization silently falls back to single-threaded mode (2-4x slower) or fails entirely with `SharedArrayBuffer is not defined`.

**How to avoid:**
1. Install `vite-plugin-cross-origin-isolation` for dev server: `npm install -D vite-plugin-cross-origin-isolation`.
2. Add to `vite.config.ts`:
   ```typescript
   import crossOriginIsolation from 'vite-plugin-cross-origin-isolation';
   export default defineConfig({
     plugins: [crossOriginIsolation()],
     // ...
   });
   ```
3. For production deployment, configure the hosting provider (Vercel, Netlify, etc.) to send both COOP and COEP headers.
4. Test in an incognito window -- extensions can interfere with header detection.

**Warning signs:**
- Console warning: `SharedArrayBuffer is not defined`
- Proving takes 2-4x longer than expected in browser
- `bb.js` initialization logs show single-thread mode

**Phase to address:**
Phase 2 -- Frontend/SDK setup. Configure Vite correctly from the start.

**Recovery cost:** LOW. Adding headers is a config change, not a code change.

---

### Pitfall 7: Vite Configuration Missing ESNext Target and Node Polyfills

**What goes wrong:**
`bb.js` uses top-level `await`, which requires Vite to target ESNext. Without this, the build fails with syntax errors or the WASM modules fail to initialize. Additionally, `bb.js` uses Node.js built-in modules (`buffer`, `crypto`, `stream`) that must be polyfilled for browser environments. Missing polyfills cause runtime crashes when the backend initializes.

**How to avoid:**
Complete Vite configuration for Noir/Barretenberg:
```typescript
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import { nodePolyfills } from 'vite-plugin-node-polyfills';
import crossOriginIsolation from 'vite-plugin-cross-origin-isolation';

export default defineConfig({
  plugins: [
    react(),
    nodePolyfills(),
    crossOriginIsolation(),
  ],
  build: {
    target: 'esnext',
  },
  optimizeDeps: {
    exclude: ['@aztec/bb.js'],
  },
  resolve: {
    alias: {
      'pino': 'pino/browser',  // Resolve pino to browser-compatible version
    },
  },
});
```

**Warning signs:**
- Build error: `Top-level await is not available in the configured target environment`
- Runtime error: `Buffer is not defined` or `process is not defined`
- `@aztec/bb.js` fails during Vite's dependency optimization step

**Phase to address:**
Phase 2 -- Frontend setup. Copy this config verbatim as the starting point.

**Recovery cost:** LOW. Configuration fix, but debugging the error messages can waste hours if you do not know the cause.

---

### Pitfall 8: Garaga Contract Declaration Cost Surprise on Testnet

**What goes wrong:**
Garaga-generated verifier contracts are large (the generated Cairo code includes circuit-specific constants, pairing check logic, and verification algorithms). Contract declaration on Starknet is priced by contract size. The declaration step can fail if the deploying account does not have enough STRK for the fee, or if the contract exceeds size limits. Developers who test only with `snforge` locally discover this only when attempting Sepolia deployment.

**How to avoid:**
1. Fund the deploying account with sufficient STRK from the Sepolia faucet (request multiple times if needed; faucets often have per-request limits).
2. Use `garaga declare --fee strk` and check the estimated fee BEFORE the actual transaction.
3. Test declaration early -- do not wait until the demo day.
4. Have a backup account pre-funded in case the primary runs out of testnet STRK.
5. If declaration is too expensive, check if a compatible Garaga verifier class hash is already declared on Sepolia (declaration is per-unique-bytecode; if someone else declared the same contract, you can deploy from their class hash).

**Warning signs:**
- `garaga declare` fails with insufficient funds error
- Declaration transaction is pending for a long time (may indicate fee too low)
- Contract size warnings during `scarb build`

**Phase to address:**
Phase 3 -- Contract deployment. Budget time for faucet funding and deployment testing.

**Recovery cost:** LOW-MEDIUM. Just need more testnet tokens, but if the faucet is rate-limited, it can delay deployment by hours.

---

### Pitfall 9: Signature Replay and Missing Nonce in Credential Verification

**What goes wrong:**
If the credential verification contract does not properly track nullifiers, a prover can submit the same proof multiple times to claim repeated verifications. More subtly, if the nullifier derivation does not include the dApp context (contract address), a proof generated for dApp A can be replayed on dApp B, breaking the unlinkability guarantee.

**How to avoid:**
1. Nullifier = Poseidon2(user_secret, credential_commitment, dapp_contract_address). The dApp address MUST be an input to the nullifier.
2. The on-chain registry MUST store used nullifiers and reject duplicates: `assert(!used_nullifiers.contains(nullifier))`.
3. The circuit MUST constrain that the nullifier is correctly derived from the inputs (not just passed as a public input without verification).
4. Test with: same proof submitted twice (must reject), same credential verified on two dApps (must produce different nullifiers), different users with same attribute (must produce different nullifiers).

**Warning signs:**
- Same proof accepted twice by the contract
- Nullifiers are identical across different dApp addresses
- Nullifier is a public input not derived inside the circuit

**Phase to address:**
Phase 1 (circuit) and Phase 3 (contract). The nullifier scheme must be designed in the circuit and enforced in the contract.

**Recovery cost:** MEDIUM-HIGH. Changing nullifier derivation requires circuit changes, contract redeployment, and client SDK updates.

---

### Pitfall 10: Noir Compiler Version Field Enforcement in Nargo.toml

**What goes wrong:**
Recent Noir versions enforce that the `compiler_version` field in `Nargo.toml` exactly matches the installed `nargo` version. If you copy an example project or update Noir without updating this field, compilation fails with a cryptic error. External dependencies (like `poseidon v0.1.1`) also require compiler compatibility -- the dependency's own `Nargo.toml` must be compatible with your compiler version.

**How to avoid:**
1. After installing Noir, immediately run `nargo --version` and set `compiler_version` in `Nargo.toml` to match exactly.
2. When adding external dependencies like `poseidon = { tag = "v0.1.1", git = "https://github.com/noir-lang/poseidon" }`, verify the dependency's `Nargo.toml` is compatible with your compiler version. Check the dependency's README for version compatibility notes.
3. Use `nargo check` after any toolchain update to catch version mismatches early.
4. Pin the `noirup` version in setup scripts: `noirup --version 1.0.0-beta.16` (not just `noirup`).

**Warning signs:**
- `nargo build` fails with "compiler version mismatch" error
- External dependency resolution fails during `nargo build`
- Different behavior on CI vs local due to different Noir versions

**Phase to address:**
Phase 0 -- Environment setup. Lock versions on Day 1.

**Recovery cost:** LOW. Just update the version field. But debugging the error can waste 30-60 minutes if you do not know about this requirement.

---

## Minor Pitfalls

### Pitfall 11: Accidental `pub` on Private Circuit Inputs

**What goes wrong:**
Marking a circuit input as `pub` (public) makes it visible to the verifier and included in the on-chain calldata. If `attribute_value`, `user_secret`, or `credential_data` is accidentally marked `pub`, the entire privacy guarantee collapses. Noir's syntax makes this easy to miss -- `fn main(x: pub Field, secret: Field)` -- the `pub` keyword is small and easily added during refactoring.

**How to avoid:**
1. Convention: public inputs go first and are clearly commented. Private inputs follow.
2. Review: after any circuit change, run `nargo info` and check the number of public inputs matches expectations.
3. Test: the generated VK encodes the number of public inputs. Verify this number is minimal (nullifier, credential_commitment, threshold, dapp_address, verification_result -- and nothing else).
4. Never use `pub` on: `user_secret`, `attribute_value`, `credential_data`, `issuer_private_key`.

**Phase to address:** Phase 1 -- Circuit development. Review public/private boundary on every change.

**Recovery cost:** LOW if caught in review. HIGH if caught after deployment (need new circuit, new verifier contract, new everything).

---

### Pitfall 12: Starknet Account Setup Complexity for Testnet

**What goes wrong:**
Starknet requires a deployed account contract even for basic operations. New developers expect to just send transactions from a funded address. Instead, you must: create an account, fund it via faucet, deploy the account contract, then use it. The address format also requires a leading `0x0` prefix that is easy to get wrong.

**How to avoid:**
1. Use Starknet Foundry's account management: `sncast account create --type oz --name test`, fund via faucet, `sncast account deploy --fee-token strk --name test`.
2. Alternatively, use an Argent X or Braavos browser wallet account for deployment.
3. Script the entire account setup in a Makefile target.
4. Save account credentials in a `.secrets` file (gitignored) with `SEPOLIA_RPC_URL`, `SEPOLIA_ACCOUNT_PRIVATE_KEY`, `SEPOLIA_ACCOUNT_ADDRESS`.

**Phase to address:** Phase 0/3 -- Environment setup and deployment.

**Recovery cost:** LOW. Just setup overhead, but can waste 1-2 hours if unexpected.

---

### Pitfall 13: Cairo Contract Access Control on Verifier and Registry

**What goes wrong:**
The `StarkShieldRegistry` contract manages trusted issuers, nullifier tracking, and verification logs. If access control is not properly implemented, anyone can register themselves as a trusted issuer or clear nullifier records. Cairo does not have Solidity-style function modifiers -- access control must be implemented manually or via OpenZeppelin Cairo contracts.

**How to avoid:**
1. Use OpenZeppelin Cairo Contracts' `Ownable` or `AccessControl` components.
2. For the registry: only the contract owner should be able to add/remove trusted issuers.
3. For nullifier tracking: nullifier storage should be append-only (no delete function).
4. For verification: anyone can call `verify`, but the proof must be valid.
5. Follow checks-effects-interactions pattern even in Cairo to prevent reentrancy.

**Phase to address:** Phase 3 -- Contract development.

**Recovery cost:** LOW-MEDIUM. Adding access control is straightforward but requires redeployment.

---

## Technical Debt Patterns

Shortcuts that seem reasonable but create long-term problems.

| Shortcut | Immediate Benefit | Long-term Cost | When Acceptable |
|----------|-------------------|----------------|-----------------|
| Hardcoding credential schema in circuit | Faster initial development, fewer generic types | Cannot add new credential types without new circuit + verifier | Acceptable for hackathon MVP with exactly 2 types |
| Skipping circuit unit tests beyond happy path | Faster iteration | Under-constrained bugs, soundness issues undiscovered | Never -- always test with malicious inputs |
| Single monolithic circuit for both credential types | One verifier contract, simpler deployment | Larger constraint count, slower proving, cannot upgrade independently | Acceptable if total constraints stay < 2^16 |
| Using `garaga verify-onchain` CLI instead of programmatic verification | Fast demo workflow | Not composable with dApp frontend | Acceptable for initial testing, must replace for demo |
| Storing all verification state in a single contract | Simple architecture | Gas costs grow with state, harder to upgrade | Acceptable for hackathon scale |
| Python-only Garaga calldata generation | Garaga Python SDK is most documented | Adds Python to the build chain, deployment scripts are language-mixed | Acceptable, but consider npm garaga package for uniformity |

## Integration Gotchas

Common mistakes when connecting components in the Noir + Garaga + Cairo + WASM stack.

| Integration | Common Mistake | Correct Approach |
|-------------|----------------|------------------|
| Noir circuit -> Garaga verifier | Using `--system ultra_keccak_honk` instead of `--system ultra_keccak_zk_honk` (missing ZK mode) | Always use `ultra_keccak_zk_honk` for privacy-preserving proofs. Non-ZK mode leaks witness data. |
| bb.js proof -> Garaga calldata | Proof format from browser bb.js differs from `bb prove` CLI output | Verify that browser-generated proofs have the same byte format as CLI proofs. Use `garaga calldata` with the exact binary output. |
| Garaga calldata -> Cairo contract | Calldata format depends on `--format` flag (array vs starkli vs snforge) | Use `--format starkli` for actual on-chain calls via starknet.js, `--format snforge` for tests |
| Noir noir_js -> bb.js in browser | Initializing Noir and Barretenberg in wrong order or without awaiting | Must `await` both WASM module initializations before creating `UltraHonkBackend`. Use `Promise.all([initACVM, initNoirC])` pattern. |
| starknet.js -> Argent X / Braavos | Using `Account` class instead of `WalletAccount` for browser wallet interaction | Use `WalletAccount` from starknet.js -- it delegates signing to the browser wallet extension. `Account` requires the private key directly. |
| Poseidon2 Noir library -> Garaga contract | Using different Poseidon2 parameter sets in circuit vs contract | Ensure both use the same Poseidon2 parameterization. The Noir `poseidon` library and Cairo `garaga` library must agree on round counts and MDS matrix. |

## Performance Traps

Patterns that work in development but fail in production or demo conditions.

| Trap | Symptoms | Prevention | When It Breaks |
|------|----------|------------|----------------|
| Testing proof generation only in Node.js, not browser | Node.js uses native Barretenberg (fast). Browser uses WASM (3-10x slower). Circuit "fast enough" in tests but too slow for demo. | Test in browser from Day 1. Use `@noir-lang/backend_barretenberg` WASM proving in integration tests. | When circuit exceeds ~30K constraints and browser proving > 30s |
| WASM single-thread fallback | Missing COOP/COEP headers cause bb.js to fall back to single-threaded WASM. Proving is 2-4x slower than multi-threaded. | Add cross-origin isolation headers to Vite dev server AND production deployment. | Immediately, on every browser test without proper headers |
| Loading full WASM modules on page load | bb.js WASM modules are ~10MB. Loading them on initial page load causes 5-10s blank screen. | Lazy-load WASM: only initialize Barretenberg when user clicks "Generate Proof". Show loading indicator. | On first page load, especially on slower connections |
| Poseidon2 hashing of large credential structs | Hashing 8 fields requires multiple Poseidon2 calls, each adding constraints. Unoptimized hashing can double circuit size. | Use Poseidon2 with appropriate state size (t=4 or t=8). Batch fields into minimal number of hash calls. The external `poseidon` library is optimized for this. | When credential struct grows beyond 4 fields |

## Security Mistakes

Domain-specific security issues for ZK credential verification.

| Mistake | Risk | Prevention |
|---------|------|------------|
| Exposing credential issuer identity in public inputs | De-anonymizes which issuer signed the credential, reducing anonymity set | Hash issuer public key with the credential commitment; only expose the commitment publicly |
| Nullifier derived without user secret | Anyone who knows the credential data can compute the nullifier and link verifications | Nullifier MUST include user's private secret: `nullifier = Poseidon2(user_secret, credential_id, dapp_address)` |
| Using Garaga contracts generated by versions < 0.17.0 | Known critical vulnerability in multi-scalar multiplications affecting proof verification | Only use Garaga >= 1.0.0. The project already specifies 1.0.1 which is safe. |
| Credential expiration check only in circuit, not on-chain | Prover can use an expired credential by providing false "current time" to the circuit | Pass block timestamp (or a verifier-provided timestamp) as a public input from the contract, not from the prover |
| Not binding proof to specific transaction/caller | Proof generated by user A could be submitted by user B | Include `get_caller_address()` or a nonce in the on-chain verification flow; alternatively bind the proof to the transaction via a signature |

## UX Pitfalls

Common user experience mistakes in ZK dApps.

| Pitfall | User Impact | Better Approach |
|---------|-------------|-----------------|
| No progress indicator during proof generation | User thinks app is frozen during 15-30s proving | Show animated progress with estimated time. Use Web Worker for proving to keep UI responsive. |
| "Proof failed" with no actionable error | User cannot recover; does not know if it is their fault or a bug | Distinguish: "credential expired", "invalid credential format", "proving failed (try again)", "verification rejected" |
| Requiring wallet connection before showing any UI | Bounces users who want to explore before committing | Show credential wallet view without wallet connection; only require wallet for on-chain submission |
| Asking user to manually input credential JSON | Error-prone, terrible demo experience | Provide demo credential loading button; pre-populate with test data for hackathon |
| WASM module download blocks UI | 10MB download with no indication hangs the page | Preload WASM modules with progress bar OR lazy-load with explicit "Preparing ZK prover..." state |

## "Looks Done But Isn't" Checklist

Things that appear complete but are missing critical pieces.

- [ ] **Circuit compiles and tests pass:** Often missing malicious input tests. Verify with crafted bad inputs that should be rejected (wrong signature, wrong attribute, expired credential).
- [ ] **Proof generates in browser:** Often tested only in Node.js. Verify in Chrome with WASM, measuring actual wall-clock time on a mid-range device.
- [ ] **Verifier contract deployed:** Often missing access control on registry functions. Verify that only authorized issuers can register, nullifiers are correctly stored and checked.
- [ ] **On-chain verification succeeds:** Often tested only with CLI `garaga verify-onchain`. Verify with browser-generated proofs submitted via starknet.js through the actual frontend.
- [ ] **Nullifier prevents double-spend:** Often tested with identical proofs but not with same-credential-different-proof. Verify that the same credential cannot produce two valid proofs with different nullifiers for the same dApp.
- [ ] **Demo flows end-to-end:** Often tested as isolated steps (generate proof, then separately call contract). Verify the complete flow: load credential -> generate proof -> submit to chain -> see verification result -> attempt replay (should fail).
- [ ] **Error states handled:** Often only happy path implemented. Verify: wallet not connected, wrong network, insufficient gas, invalid credential format, expired credential, already-used nullifier.

## Recovery Strategies

When pitfalls occur despite prevention, how to recover.

| Pitfall | Recovery Cost | Recovery Steps |
|---------|---------------|----------------|
| Version mismatch (Pitfall 1) | HIGH (2-3 days) | Downgrade all tools to Garaga-specified versions, regenerate VK, re-prove, regenerate verifier contract, redeploy |
| Constraint ceiling (Pitfall 2) | HIGH (1-2 days) | Drop least critical feature (expiration check first), simplify hash scheme, or split into two smaller circuits |
| Small-domain brute force (Pitfall 3) | HIGH (1-2 days) | Redesign public outputs, add blinding factors to hashes, regenerate entire pipeline |
| Python version (Pitfall 4) | LOW (1-2 hours) | Install correct Python version via pyenv, regenerate affected artifacts |
| Under-constrained circuit (Pitfall 5) | MEDIUM (4-8 hours) | Add missing constraints, re-test with adversarial inputs, regenerate proofs |
| Missing COOP/COEP headers (Pitfall 6) | LOW (30 min) | Add vite plugin and production server headers |
| Vite config (Pitfall 7) | LOW (30 min) | Copy known-good config, clear node_modules, rebuild |
| Declaration cost (Pitfall 8) | LOW (1-2 hours) | Request more testnet tokens, or reuse existing class hash |
| Signature replay (Pitfall 9) | MEDIUM-HIGH (1 day) | Fix nullifier derivation in circuit and contract, redeploy |
| Compiler version field (Pitfall 10) | LOW (15 min) | Update Nargo.toml field to match installed version |
| Accidental pub (Pitfall 11) | LOW-HIGH (varies) | Remove pub keyword, regenerate pipeline if already deployed |
| Account setup (Pitfall 12) | LOW (1 hour) | Follow sncast account creation workflow |
| Access control (Pitfall 13) | LOW-MEDIUM (2-4 hours) | Add OZ AccessControl, redeploy |

## Pitfall-to-Phase Mapping

How roadmap phases should address these pitfalls.

| Pitfall | Prevention Phase | Verification |
|---------|------------------|--------------|
| Version mismatch (1) | Phase 0: Environment | Full prove-verify loop completes end-to-end before circuit development begins |
| Constraint ceiling (2) | Phase 1: Circuit | `nargo info` gate count checked after each feature; browser proving time measured |
| Small-domain brute force (3) | Phase 1: Circuit Design | Audit all `pub` outputs; verify none are deterministic functions of small-domain values |
| Python version (4) | Phase 0: Environment | `garaga gen --help` succeeds in the correct Python virtualenv |
| Under-constrained (5) | Phase 1: Circuit | Adversarial tests included in circuit test suite; constraint count matches expectations |
| COOP/COEP headers (6) | Phase 2: Frontend | `SharedArrayBuffer` available in browser console; multi-threaded proving confirmed |
| Vite config (7) | Phase 2: Frontend | Noir proof generation works in browser dev environment without errors |
| Declaration cost (8) | Phase 3: Deployment | Contract declared and deployed on Sepolia before integration testing begins |
| Signature replay (9) | Phase 1+3: Circuit+Contract | Same proof rejected on resubmission; different nullifiers for different dApps |
| Compiler version (10) | Phase 0: Environment | `nargo build` succeeds with all dependencies resolved |
| Accidental pub (11) | Phase 1: Circuit | Public input count matches spec (5 or fewer); no private data in VK public input slots |
| Account setup (12) | Phase 0: Environment | sncast account deployed and funded on Sepolia |
| Access control (13) | Phase 3: Contract | Registry functions restricted; unauthorized calls revert |

## Hackathon-Specific Time Traps

Issues that are particularly dangerous on a 14-day compressed timeline.

| Time Trap | Expected Time Waste | Prevention |
|-----------|--------------------|-----------|
| Debugging version mismatches across 6+ tools | 4-8 hours | Lock ALL versions Day 1, validate full pipeline before coding |
| Starknet Sepolia faucet rate limits / downtime | 2-4 hours | Fund multiple accounts early, request tokens daily, have backup RPC endpoints |
| Garaga CLI producing valid-looking but wrong calldata | 4-12 hours (hard to debug) | Test on-chain verification on Day 2-3, not Day 12 |
| Browser WASM module loading issues in production | 2-4 hours | Test on deployed URL (not just localhost) by end of Week 1 |
| Demo video re-recording due to testnet issues | 2-4 hours | Record demo with pre-generated proofs as backup; have fallback if testnet is slow |
| Scope creep to 3rd credential type | 8-16 hours | Hard stop at 2 types. Third type is post-hackathon. No exceptions. |

## Sources

- [OpenZeppelin: Developer's Guide to Building Safe Noir Circuits](https://www.openzeppelin.com/news/developer-guide-to-building-safe-noir-circuits) -- HIGH confidence: authoritative audit firm, published September 2025
- [Garaga SDK Documentation](https://garaga.gitbook.io/garaga/) -- MEDIUM confidence: official docs but sparse on edge cases
- [Garaga v1.0.1 Release Notes](https://github.com/keep-starknet-strange/garaga/releases) -- HIGH confidence: official release history with security advisories
- [Garaga Noir Verifier Documentation](https://garaga.gitbook.io/garaga/smart-contract-generators/noir) -- HIGH confidence: official step-by-step with exact version pins
- [sn-noir-quickstart Workshop](https://github.com/m-kus/sn-noir-quickstart) -- MEDIUM confidence: community workshop, slightly outdated version pins
- [Noir Benchmarks (Savio-Sou)](https://github.com/Savio-Sou/noir-benchmarks) -- MEDIUM confidence: community benchmarks with specific numbers
- [Noir Documentation: Building a Web App](https://noir-lang.org/docs/tutorials/noirjs_app/) -- HIGH confidence: official Noir docs
- [Noir Documentation: Unconstrained Functions](https://noir-lang.org/docs/noir/concepts/unconstrained) -- HIGH confidence: official docs
- [Aztec Blog: Unconstrained Functions in Noir](https://aztec.network/blog/unconstrained-functions-in-noir) -- HIGH confidence: Noir creator's blog
- [Aztec Blog: Client-side Proof Generation](https://aztec.network/blog/client-side-proof-generation) -- MEDIUM confidence: architectural overview without specific numbers
- [Noir Issue #2543: Break large programs into recursive chunks](https://github.com/noir-lang/noir/issues/2543) -- HIGH confidence: official issue documenting 2^19 WASM limit
- [Cairo Security Flaws (Oxor.io)](https://oxor.io/blog/2024-08-16-cairo-security-flaws/) -- MEDIUM confidence: security firm analysis
- [Starknet Cairo Book: Smart Contract Security](https://www.starknet.io/cairo-book/ch104-00-starknet-smart-contracts-security.html) -- HIGH confidence: official Starknet documentation
- [TACEO Blog: Poseidon2 for Noir](https://blog.taceo.io/poseidon2-for-noir/) -- MEDIUM confidence: library author's blog with benchmark data
- [Noir Poseidon Library](https://github.com/noir-lang/poseidon) -- HIGH confidence: official Noir-maintained library
- [Cyfrin: ZK Mixer Nullifier Hash](https://updraft.cyfrin.io/courses/noir-programming-and-zk-circuits/zk-mixer/nullifier-hash) -- MEDIUM confidence: educational course with practical examples
- [NAVe: Formally Verifying Noir Programs](https://arxiv.org/abs/2601.09372) -- HIGH confidence: peer-reviewed research, January 2026

---
*Pitfalls research for: ZK Credential Verification on Starknet (Noir + Garaga + Cairo + WASM)*
*Researched: 2026-02-14*
